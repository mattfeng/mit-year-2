\documentclass{6046}

\usepackage{float}
\usepackage{algorithm}
\usepackage{algpseudocode}

\author{Matthew Feng}
\problem{7}
% \problem{A} means Problem Set A.
\collab{James Lin}
% or give names, e.g., \collab{Alyssa P. Hacker and A. Student}

\begin{document}

\section*{Problem 1}
\subsection*{(a)}

\subsection*{(b)}
Consider the array $[1, 2, 3, ..., n]$ that is rotated by
$\frac{n}{2}$ indices, so that the resulting array $A$ is
$[n/2, n/2 + 1, ..., n - 2, n - 1, n, 1, 2, 3, ... n/2 - 1]$.
$A$ is not mostly sorted, since only by removing (at least) 
$n/2$ elements can we obtain a sorted array.

\subsection*{(c)}


\subsection*{(d)}
Suppose (for the sake of contradiction) that $A$ is {\bf not}
mostly sorted, yet more than $\frac{9}{10}n$
indices can pass {\sc Binary-Search-Test}. We can order these indices
in increasing order $\{i_1, i_2, i_3, ..., i_{9n/10}, i_{9n/10 + 1}, ...\}$.
Then, by the property demonstrated in part (c), we know that
$A[i_1] < A[i_2] < A[i_3] < ... < A[i_{9n/10}] < A[i_{9n/10 + 1}]$.
But that means that the array $A$ is mostly sorted.
This is a contradiction, and thus no more than $\frac{9}{10}n$ can
pass {\sc Binary-Search-Test} for an array $A$ that is
not mostly sorted.

\subsection*{(e)}
We can now use {\sc Binary-Search-Test} as a subroutine for our
algorithm. The algorithm is as follows:

\begin{algorithm}[H]
  \caption{Check if an array is sorted using randomization}\label{RandCheck}
  \begin{algorithmic}[0]
    \Function{Check-Sorted}{$A$}
    \For{100 iterations}
        \State generate random index $i \in [0, n - 1]$
        \State success $\leftarrow$ \Call{Binary-Search-Test}{$A$, $i$}
        \If{success $\not=$ True}
            \State \Return ``UNSORTED''
        \EndIf
    \EndFor
    \State \Return ``SORTED''
    \EndFunction
  \end{algorithmic}
\end{algorithm}

The main idea behind the algorithm is that if {\sc Binary-Search-Test}
fails for any index $i \in [0, n - 1]$, then $A$ is not sorted.
Similarly, the more times {\sc Binary-Search-Test} succeeds, the
more probable that $A$ is sorted.

The algorithm calls {\sc Binary-Search-Test} with a random index;
if {\sc Binary-Search-Test} fails, then we know that the array
$A$ cannot be sorted, and so we return ``UNSORTED.'' However,
if our tests succeed a sufficient number of times, then we
can be fairly confident that the array is sorted, and thus
we return ``SORTED'' with some probability that we will
be incorrect.

Formally, we can argue the correctness of this algorithm
through casework. There are three cases:
\vspace{-1.5em}

\paragraph{Case 1.} $A$ is sorted.
\vspace{-0.75em}

Since $A$ is sorted, {\sc Binary-Search-Test} will always succeed,
and thus we will always return ``SORTED'', as desired.
\vspace{-1em}

\paragraph{Case 2.} $A$ is mostly sorted, but not (completely) sorted.
\vspace{-0.75em}

In this case, our algorithm may return ``SORTED'' or ``UNSORTED'',
but we don't care what the output is; thus, this case is
satisfactory as well.
\vspace{-1em}

\paragraph{Case 3.} $A$ is not mostly sorted.
\vspace{-0.75em}

First, if $A$ is not mostly sorted, our algorithm fails
if it outputs ``SORTED.'' This means that our algorithm
fails if all $100$ calls to {\sc Binary-Search-Test} succeed.

Next, since $A$ is not mostly sorted, by the fact shown in (d) that
{\sc Binary-Search-Test} will succeed on no more than
$\frac{9}{10}n$ indices, we can say that
for a not-mostly-sorted array, each individual call to
{\sc Binary-Search-Test} will succeed {\bf with probability $\le \frac{9}{10}$}.

Thus, the chance that {\it every call} of
{\sc Binary-Search-Test} on $A$ succeeds, for $k$ calls,
is bounded above by $(\frac{9}{10})^k$. For a large
enough constant $k$ (in particular, $k = 22$), this probability
drops below $\frac{1}{10}$. In other words, the probability that
our algorithm fails for this case is less than $\frac{1}{10}$,
for all $k \ge 22$. Since we set $k = 100$, the probability that
our algorithm returns the incorrect output is well below $\frac{1}{10}$.

\vspace{1.5em}

Since $A$ must fall in one of these three cases,
and that our algorithm succeeds all the time
for cases $1$ and $2$, and fails
with very little probability for case $3$,
our algorithm fits the specifications. Furthermore,
since we make a constant number of calls to {\sc Binary-Search-Test},
which runs in $O(\log n)$ time, our algorithm runs in
$O(1) \times O(\log n)$ time complexity, which remains $O(\log n)$,
as desired.

\section*{Problem 2}
\subsection*{(a)}

\subsection*{(b)}

\subsection*{(c)}

\subsection*{(d)}
First, view every edge as two different halves: an outgoing, source
``half,'' and an incoming, destination ``half.'' Every
edge must have both parts. For a digraph
$G = (V, E)$, if the out-degree of every node is
exactly $d$, then there are exactly $|V|d$ outgoing ``halves''.
Consequently, there must be exactly $|V|d$ incoming ``halves''.
Since the in-degree of any node must be $\le d$, the
total number of incoming ``halves'' that can exist in $G$
is $\le |V|d$, with equality if and only if every node has
an in-degree of $d$. Thus, since we have exactly $|V|d$ incoming
halves, this implies that every node has an in-degree of $d$.

\subsection*{(e)}
If we can show that any node in the Markov chain as described above
(i.e. on the node set $V(G) \times \mathcal{T}$) can have
in-degree at most $d$, and we know that every node in the Markov
chain has out-degree of $d$ (since every node $v \in V(G)$
is connected to $d$ neighbors), then by Part (d) we know
that the in-degree of every node must be $d$.

We first note that in order for a transition to be valid,
the edge $(u, v)$ must exist in $E(G)$. That is to say,
$v$ must be a neighbor of $u$ in $G$.

Next, we will prove a lemma.
\vspace{-1em}
\begin{lemma}
    There exists a unique transition from $v$ to $(u, T)$;
    that is, there exists a unique $T'$ such that
    $(v, T') \rightarrow (u, T)$ is a valid transition.
\end{lemma}

\begin{proof}
Suppose there exists two different spanning trees $T'$ and $T''$,
for which both $(v, T') \rightarrow (u, T)$ and
$(v, T'') \rightarrow (u, T)$ are valid. We can divide
$T$ into two trees by removing edge $(u, v)$; let $T_u$
be the tree rooted at $u$, and $T_v$ be the tree
rooted at $v$.
\end{proof}

Thus, from this lemma, we can bound the number of valid
transitions to $(u, T)$ by the number of neighbors $u$
has in $G$, since each neighbor can only contribute one
transition to $(u, T)$!

Thus, since $u \in V(G)$ is connected to exactly
$d$ neighbors, the number of transitions that
end at $(u, T)$ is upper bounded by $d$. This is
exactly what we wanted to show; as such, this fact implies,
by Part (d), that the in-degree of every node in the
Markov chain is exactly $d$.


\end{document}

